{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "guided-content",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "module_path1 = os.path.abspath(os.path.join('../modules/'))\n",
    "if module_path1 not in sys.path:\n",
    "    sys.path.append(module_path1)\n",
    "\n",
    "import mongo_db_interface as mongo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-smoke",
   "metadata": {},
   "source": [
    "### This notebook demonstrates some of the functions of the BETO_NLP module `mongo_db_handler`\n",
    "\n",
    "This class facilitates connections to the MongoDB Atlas database that holds the corpus. To connect to the DB, you need to first:\n",
    "\n",
    " - Ensure you are a registered user of the cluster and collection with a password\n",
    " - Ensure your IP address is whitelisted. If you use a VPN, make sure that IP address is also whitelisted\n",
    " \n",
    "On initialization of the `MongoDBHandler()` class, you need to pass the correct username and password as strings. These are inserted into the client connection string. If you are using a MongoDB cluster and/or project that is different from the default, make sure to modify the names in the client connection string as shown below:\n",
    "\n",
    "\n",
    "\n",
    "In MongoDBHandler.__init__(), replace `practice-general-corpus` with your preferred cluster and\n",
    "replace `BETO_corpus_practice` with your preferred project\n",
    "\n",
    "`client = MongoClient('mongodb+srv://' + user + ':' + password + '@practice-general-corpus.qt2hh.mongodb.net/BETO_corpus_practice?retryWrites=true&w=majority')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "seasonal-cassette",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load user and password from local file\n",
    "with open('/Users/wesleytatum/Desktop/post_doc/BETO/mongo_passwords.json', 'r') as f:\n",
    "    mongo_passwords = json.load(f)\n",
    "    f.close()\n",
    "    \n",
    "user = mongo_passwords['user']\n",
    "password = mongo_passwords['password']\n",
    "    \n",
    "#initialize MongoDBHandler()\n",
    "mongo_handler = mongo.MongoDBHandler(user, password)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-knitting",
   "metadata": {},
   "source": [
    "In this tutorial, we will access all of the articles saved in a practice corpus. They were all scraped from the Royal Society of Chemistry (RSC) using the `rsc_corpus_gen` module in this repo. Originally, the articles have the following 'blobs' of data associated with them:\n",
    "\n",
    " - '_id': Their unique ObjectID. In the case of articles, this corresponds to the DOI\n",
    " - 'doi': This is a redundant datafield that arises due to scraping\n",
    " - 'title': The title of the article\n",
    " - 'abstract': If the article has an abstract, it is listed in a string here. Otherwise the string states \"no abstract\"\n",
    " - 'html': The raw HTML of the article saved as a string. This allows access to figures and tables in the future\n",
    " \n",
    "Because we are expecting our corpus to have articles from multiple publishers, we would like to add an additional field:\n",
    "\n",
    " - 'publisher': In this case, the value will be 'RSC'\n",
    "\n",
    "The process to add this new field and update the database is outlined below. It's general structure is generalizable to adding any new field to the article objects:\n",
    "\n",
    " 1. Obtain all objects you wish to add the field to. Their \"_id's\" are retuned as an iterable list.\n",
    "     - This can be done to all articles or any subset by filtering with a particular field (_e.g._ publisher, keyword)\n",
    " 2. Access a single object at a time and perform the desired function on a field of the object and add the results to the object.\n",
    "     - In this case we add the 'publisher' field. Instead, we could add fields for 'keywords', 'article_string', or 'compounds'\n",
    " 3. Update and upload the object in the MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "clear-audit",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 318/318 [05:06<00:00,  1.29it/s]"
     ]
    }
   ],
   "source": [
    "#1. Get a list of all articles in the DB\n",
    "doi_list = mongo_handler.retrieve_all_article_doi()\n",
    "\n",
    "#2. Iterate through articles and add new field\n",
    "\n",
    "pbar = tqdm(total = len(doi_list), position = 0)\n",
    "\n",
    "for doi in doi_list:\n",
    "    article = mongo_handler.retrieve_doc_by_doi(doi)\n",
    "    \n",
    "    #3. Update and upload the article\n",
    "    article['publisher'] = 'RSC'\n",
    "    mongo_handler.upload_article_document(article)\n",
    "    \n",
    "    pbar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-horse",
   "metadata": {},
   "source": [
    "Now we see that the documents have the new field added to them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "normal-petersburg",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['_id', 'doi', 'title', 'abstract', 'html', 'upload_timestamp', 'publisher'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'RSC'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = mongo_handler.retrieve_doc_by_doi(doi_list[28])\n",
    "print(article.keys())\n",
    "article['publisher']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-gravity",
   "metadata": {},
   "source": [
    "Iterating through all of the documents is a slow task, though. Each iteration of the above loop took an average of 1.29 seconds. Luckily we're working with a small corpus. In the future, though, we want to be working with >30,000 documents, which would take at least 10.75 hours just to add on a single new field. Obviously, this is prohibitively slow.\n",
    "\n",
    "MongoDB has functions to address this, such as `update_many()`, which allows you to find all documents that match a filter and update them. This is typically used for reassigning a field value to a single pre-determined value for a collection of documents that are matched by a query filter (like `corpus.find({'publisher':'RSC'})`). However, it is much more complicated to apply a custom function on a field of the documents and add the results as a new field. There are a few different ways to do this, but it seems that the fastest is to write the custom function in JavaScript and us the `forEach()` function. Unfortunately, the `forEach()` and `map()` functions are only available in the MongoDB shell, and not the pymongo driver interface. For those interested, this quick, powerful approach is shown below to add the field `keywords`.\n",
    "\n",
    "To do this, we will use a pre-determined list of keywords and a new field containing all keywords that find matches in the `article['html']` value. This example corpus was scraped looking for 'conjugated polymers', so the keywords selected will correspond to these materials and their applications.\n",
    "\n",
    "To access the object that interfaces with the MongoDB database for these custom queries and operations, assign the return of `MongoDBHandler.return_client_corpus_object()` to a variable. This allows collection-level operations to be performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "confused-computer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['polymer', 'photovoltaic']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define our keywords that we are searching for\n",
    "keywords = ['chemistry', 'polymer', 'photovoltaic', 'OPV', 'semiconductor', 'transister',\n",
    "            'OFET', 'OTFT', 'ternary blend', 'nonfullerene acceptor', 'non-fullerene acceptor',\n",
    "            'thermoelectric', 'LED', 'sensor', 'donor', 'acceptor', 'copolymer']\n",
    "\n",
    "#This is the Python version of the custom function that finds keyword matches\n",
    "def re_keyword_match(keyword_list, html):\n",
    "    matches = re.findall(r\"(?=(\"+'|'.join(keyword_list)+r\"))\", html)\n",
    "    return matches\n",
    "\n",
    "test_string = 'the polymers were used in photovoltaic devices'\n",
    "\n",
    "kws = re_keyword_match(keywords, test_string)\n",
    "\n",
    "kws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-custody",
   "metadata": {},
   "source": [
    "Converting the python function to a JavaScript function will allow the MongoDB servers themselves to apply the function, eliminating the need to download it into local memory and re-uploading the updated object. Shown below is the JavaScript translation of the `re_keyword_match` function defined above:\n",
    "\n",
    "```\n",
    "function (doc) {\n",
    "        var keyword_list = ['chemistry', 'polymer', 'photovoltaic', 'OPV', 'semiconductor', 'transister', 'OFET', 'OTFT', 'ternary blend', 'nonfullerene acceptor', 'non-fullerene acceptor', 'thermoelectric', 'LED', 'sensor', 'donor', 'acceptor', 'copolymer'];\n",
    "        const regexp = new RegExp(keyword_list.join(\"|\", 'gi'));\n",
    "        const str = doc.html;\n",
    "        const matches = str.matchAll(regexp);\n",
    "        corpus.update(\n",
    "            {'_id':'doc._id'},\n",
    "            {'$set':{'keywords':matches}}\n",
    "        );\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "minor-arrest",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Cursor' object has no attribute 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1bac66c4f6f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#perform our query and apply the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m corpus.find({'publisher':'RSC'}).map(bson.Code('''\n\u001b[0m\u001b[1;32m      6\u001b[0m     function (doc) {\n\u001b[1;32m      7\u001b[0m         \u001b[0mvar\u001b[0m \u001b[0mkeyword_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'chemistry'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'polymer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'photovoltaic'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'OPV'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'semiconductor'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'transister'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'OFET'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'OTFT'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ternary blend'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nonfullerene acceptor'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'non-fullerene acceptor'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'thermoelectric'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LED'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sensor'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'donor'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'acceptor'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'copolymer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Cursor' object has no attribute 'map'"
     ]
    }
   ],
   "source": [
    "#get the corpus collection object\n",
    "corpus = mongo_handler.return_client_corpus_object()\n",
    "\n",
    "#perform our query and apply the function\n",
    "corpus.find({'publisher':'RSC'}).map(\n",
    "    function (doc) {\n",
    "        var keyword_list = ['chemistry', 'polymer', 'photovoltaic', 'OPV', 'semiconductor', 'transister', 'OFET', 'OTFT', 'ternary blend', 'nonfullerene acceptor', 'non-fullerene acceptor', 'thermoelectric', 'LED', 'sensor', 'donor', 'acceptor', 'copolymer'];\n",
    "        const regexp = new RegExp(keyword_list.join(\"|\", 'gi'));\n",
    "        const str = doc.html;\n",
    "        const matches = str.matchAll(regexp);\n",
    "        corpus.update(\n",
    "            {'_id':'doc._id'},\n",
    "            {'$set':{'keywords':matches}}\n",
    "        );\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-pitch",
   "metadata": {},
   "source": [
    "pymongo cursors have way fewer functions... probably just do the multi-threading.\n",
    "above approach only works in MongoDB shell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respiratory-grain",
   "metadata": {},
   "source": [
    "In order to perform these functions purely in the python interface, you can use a multi-threading approach to be able to speed up the process. This allows you to utilize multiple cores on your computer to run the code and iterations in parallel. This requires the use of the pymongo function `parallel_scan()`.\n",
    "\n",
    "To demonstrate this approach, we add the `keywords` field again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "mechanical-upgrade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define our keywords that we are searching for\n",
    "keywords = ['chemistry', 'polymer', 'photovoltaic', 'OPV', 'semiconductor', 'transister',\n",
    "            'OFET', 'OTFT', 'ternary blend', 'nonfullerene acceptor', 'non-fullerene acceptor',\n",
    "            'thermoelectric', 'LED', 'sensor', 'donor', 'acceptor', 'copolymer']\n",
    "\n",
    "\n",
    "def keyword_match(cursor):\n",
    "    \n",
    "    for row in cursor.batch_size(200):\n",
    "        matches = re.findall(r\"(?=(\"+'|'.join(keyword_list)+r\"))\", html)\n",
    "        db.collection.update_one({'_id': row['_id']}, \n",
    "                                 {'$set': {'keywords': matches}},\n",
    "                                 upsert=True)\n",
    "\n",
    "\n",
    "def add_keywords(num_threads=4):\n",
    "\n",
    "    # Get up to max 'num_threads' cursors.\n",
    "    cursors = corpus.parallel_scan(num_threads)\n",
    "    threads = [threading.Thread(target=keyword_match, args=(cursor,)) for cursor in cursors]\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.start()\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "patient-seattle",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-bf15af527b5a>:19: DeprecationWarning: parallel_scan is deprecated. MongoDB 4.2 will remove the parallelCollectionScan command.\n",
      "  cursors = corpus.parallel_scan(num_threads)\n"
     ]
    },
    {
     "ename": "OperationFailure",
     "evalue": "CMD_NOT_ALLOWED: parallelCollectionScan, full error: {'ok': 0, 'errmsg': 'CMD_NOT_ALLOWED: parallelCollectionScan', 'code': 8000, 'codeName': 'AtlasError'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationFailure\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9ce2fe3395b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#call the above functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0madd_keywords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-bf15af527b5a>\u001b[0m in \u001b[0;36madd_keywords\u001b[0;34m(num_threads)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Get up to max 'num_threads' cursors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mcursors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_scan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_threads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mthreads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeyword_match\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcursor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcursors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/beto/lib/python3.8/site-packages/pymongo/collection.py\u001b[0m in \u001b[0;36mparallel_scan\u001b[0;34m(self, num_cursors, session, **kwargs)\u001b[0m\n\u001b[1;32m   1625\u001b[0m             \u001b[0;31m# We call sock_info.command here directly, instead of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1626\u001b[0m             \u001b[0;31m# calling self._command to avoid using an implicit session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1627\u001b[0;31m             result = sock_info.command(\n\u001b[0m\u001b[1;32m   1628\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__database\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m                 \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/beto/lib/python3.8/site-packages/pymongo/pool.py\u001b[0m in \u001b[0;36mcommand\u001b[0;34m(self, dbname, spec, slave_ok, read_preference, codec_options, check, allowable_errors, check_keys, read_concern, write_concern, parse_write_concern_error, collation, session, client, retryable_write, publish_events, user_fields, exhaust_allowed)\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_not_writable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munacknowledged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m             return command(self, dbname, spec, slave_ok,\n\u001b[0m\u001b[1;32m    684\u001b[0m                            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_mongos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_preference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcodec_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m                            \u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowable_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/beto/lib/python3.8/site-packages/pymongo/network.py\u001b[0m in \u001b[0;36mcommand\u001b[0;34m(sock_info, dbname, spec, slave_ok, is_mongos, read_preference, codec_options, session, client, check, allowable_errors, address, check_keys, listeners, max_bson_size, read_concern, parse_write_concern_error, collation, compression_ctx, use_op_msg, unacknowledged, user_fields, exhaust_allowed)\u001b[0m\n\u001b[1;32m    157\u001b[0m                 \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m                 helpers._check_command_response(\n\u001b[0m\u001b[1;32m    160\u001b[0m                     \u001b[0mresponse_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msock_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_wire_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowable_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m                     parse_write_concern_error=parse_write_concern_error)\n",
      "\u001b[0;32m~/opt/anaconda3/envs/beto/lib/python3.8/site-packages/pymongo/helpers.py\u001b[0m in \u001b[0;36m_check_command_response\u001b[0;34m(response, max_wire_version, allowable_errors, parse_write_concern_error)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mCursorNotFound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_wire_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mOperationFailure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_wire_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationFailure\u001b[0m: CMD_NOT_ALLOWED: parallelCollectionScan, full error: {'ok': 0, 'errmsg': 'CMD_NOT_ALLOWED: parallelCollectionScan', 'code': 8000, 'codeName': 'AtlasError'}"
     ]
    }
   ],
   "source": [
    "#get the corpus collection object\n",
    "corpus = mongo_handler.return_client_corpus_object()\n",
    "\n",
    "#call the above functions\n",
    "add_keywords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-allowance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
