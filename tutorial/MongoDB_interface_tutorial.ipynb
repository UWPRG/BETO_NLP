{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cardiac-electronics",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "module_path1 = os.path.abspath(os.path.join('../modules/'))\n",
    "if module_path1 not in sys.path:\n",
    "    sys.path.append(module_path1)\n",
    "\n",
    "import mongo_db_interface as mongo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "natural-speech",
   "metadata": {},
   "source": [
    "### This notebook demonstrates some of the functions of the BETO_NLP module `mongo_db_handler`\n",
    "\n",
    "This class facilitates connections to the MongoDB Atlas database that holds the corpus. To connect to the DB, you need to first:\n",
    "\n",
    " - Ensure you are a registered user of the cluster and collection with a password\n",
    " - Ensure your IP address is whitelisted. If you use a VPN, make sure that IP address is also whitelisted\n",
    " \n",
    "On initialization of the `MongoDBHandler()` class, you need to pass the correct username and password as strings. These are inserted into the client connection string. If you are using a MongoDB cluster and/or project that is different from the default, make sure to modify the names in the client connection string as shown below:\n",
    "\n",
    "\n",
    "\n",
    "In MongoDBHandler.__init__(), replace `practice-general-corpus` with your preferred cluster and\n",
    "replace `BETO_corpus_practice` with your preferred project\n",
    "\n",
    "`client = MongoClient('mongodb+srv://' + user + ':' + password + '@practice-general-corpus.qt2hh.mongodb.net/BETO_corpus_practice?retryWrites=true&w=majority')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cardiovascular-zimbabwe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load user and password from local file\n",
    "with open('/Users/wesleytatum/Desktop/post_doc/BETO/mongo_passwords.json', 'r') as f:\n",
    "    mongo_passwords = json.load(f)\n",
    "    f.close()\n",
    "    \n",
    "user = mongo_passwords['user']\n",
    "password = mongo_passwords['password']\n",
    "    \n",
    "#initialize MongoDBHandler()\n",
    "mongo_handler = mongo.MongoDBHandler(user, password)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-coast",
   "metadata": {},
   "source": [
    "In this tutorial, we will access all of the articles saved in a practice corpus. They were all scraped from the Royal Society of Chemistry (RSC) using the `rsc_corpus_gen` module in this repo. Originally, the articles have the following 'blobs' of data associated with them:\n",
    "\n",
    " - '_id': Their unique ObjectID. In the case of articles, this corresponds to the DOI\n",
    " - 'doi': This is a redundant datafield that arises due to scraping\n",
    " - 'title': The title of the article\n",
    " - 'abstract': If the article has an abstract, it is listed in a string here. Otherwise the string states \"no abstract\"\n",
    " - 'html': The raw HTML of the article saved as a string. This allows access to figures and tables in the future\n",
    " \n",
    "Because we are expecting our corpus to have articles from multiple publishers, we would like to add an additional field:\n",
    "\n",
    " - 'publisher': In this case, the value will be 'RSC'\n",
    "\n",
    "The process to add this new field and update the database is outlined below. It's general structure is generalizable to adding any new field to the article objects:\n",
    "\n",
    " 1. Obtain all objects you wish to add the field to. Their \"_id's\" are retuned as an iterable list.\n",
    "     - This can be done to all articles or any subset by filtering with a particular field (_e.g._ publisher, keyword)\n",
    " 2. Access a single object at a time and perform the desired function on a field of the object and add the results to the object.\n",
    "     - In this case we add the 'publisher' field. Instead, we could add fields for 'keywords', 'article_string', or 'compounds'\n",
    " 3. Update and upload the object in the MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afraid-terror",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 318/318 [05:06<00:00,  1.29it/s]"
     ]
    }
   ],
   "source": [
    "#1. Get a list of all articles in the DB\n",
    "doi_list = mongo_handler.retrieve_all_article_doi()\n",
    "\n",
    "#2. Iterate through articles and add new field\n",
    "\n",
    "pbar = tqdm(total = len(doi_list), position = 0)\n",
    "\n",
    "for doi in doi_list:\n",
    "    article = mongo_handler.retrieve_doc_by_doi(doi)\n",
    "    \n",
    "    #3. Update and upload the article\n",
    "    article['publisher'] = 'RSC'\n",
    "    mongo_handler.upload_article_document(article)\n",
    "    \n",
    "    pbar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-cloud",
   "metadata": {},
   "source": [
    "Now we see that the documents have the new field added to them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "vocational-nickel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['_id', 'doi', 'title', 'abstract', 'html', 'upload_timestamp', 'publisher'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'RSC'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = mongo_handler.retrieve_doc_by_doi(doi_list[28])\n",
    "print(article.keys())\n",
    "article['publisher']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-championship",
   "metadata": {},
   "source": [
    "Iterating through all of the documents is a slow task, though. Each iteration of the above loop took an average of 1.29 seconds. Luckily we're working with a small corpus. In the future, though, we want to be working with >30,000 documents, which would take at least 10.75 hours just to add on a single new field. Obviously, this is prohibitively slow.\n",
    "\n",
    "MongoDB has functions to address this, such as `update_many()`, which allows you to find all documents that match a filter and update them. This is typically used for reassigning a field value to a single pre-determined value for a collection of documents that are matched by a query filter (like `corpus.find({'publisher':'RSC'})`). However, it is much more complicated to apply a custom function on a field of the documents and add the results as a new field. There are a few different ways to do this, but it seems that the fastest is to write the custom function in JavaScript and us the `forEach()` function.\n",
    "\n",
    "This process is shown below to add the field `keywords`. To do this, we will use a pre-determined list of keywords and a new field containing all keywords that find matches in the `article['html']` value. This example corpus was scraped looking for 'conjugated polymers', so the keywords selected will correspond to these materials and their applications.\n",
    "\n",
    "To access the object that interfaces with the MongoDB database for these custom queries and operations, assign the return of `MongoDBHandler.return_client_corpus_object()` to a variable. This allows collection-level operations to be performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "entitled-science",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['polymer', 'photovoltaic']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define our keywords that we are searching for\n",
    "keywords = ['chemistry', 'polymer', 'photovoltaic', 'OPV', 'semiconductor', 'transister',\n",
    "            'OFET', 'OTFT', 'ternary blend', 'nonfullerene acceptor', 'non-fullerene acceptor',\n",
    "            'thermoelectric', 'LED', 'sensor', 'donor', 'acceptor', 'copolymer']\n",
    "\n",
    "#This is the Python version of the custom function that finds keyword matches\n",
    "def re_keyword_match(keyword_list, html):\n",
    "    matches = re.findall(r\"(?=(\"+'|'.join(keyword_list)+r\"))\", html)\n",
    "    return matches\n",
    "\n",
    "test_string = 'the polymers were used in photovoltaic devices'\n",
    "\n",
    "kws = re_keyword_match(keywords, test_string)\n",
    "\n",
    "kws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-trinity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-mathematics",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = mongo_handler.return_client_corpus_object()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-semiconductor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
